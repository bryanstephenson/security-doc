<?xml version="1.0" encoding="UTF-8"?>
<section xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink"
  version="5.0"
  xml:id="data-processing-configuration-and-hardening">
  <?dbhtml stop-chunking?>
  <title>Configuration and hardening</title>
  <para>
    There are several configuration options and deployment strategies that
    can improve security in the Data processing service. The service
    controller is configured through a main configuration file and one or
    more policy files. Installations that are using the data-locality
    features will also have two additional files to specify the physical
    location of Compute and Object Storage nodes.
  </para>
  <section xml:id="data-processing-configuration-and-hardening-tls">
    <title>TLS</title>
    <para>
      The Data processing service controller, like many other OpenStack
      controllers, can be configured to require TLS connections.
    </para>
    <para>
      Pre-Kilo releases will require a TLS proxy as the controller does not
      allow direct TLS connections. Configuring TLS proxies is
      covered in <xref linkend="tls-proxies-and-http-services"/>, and we
      recommend following the advice there to create this type of
      installation.
    </para>
    <para>
      From the Kilo release onward the data processing controller allows
      direct TLS connections. Enabling this behavior requires some small
      adjustments to the controller configuration file. For any post-Juno
      installation we recommend enabling the direct TLS connections in
      the controller configuration.
    </para>
    <section xml:id="data-processing-configuration-and-hardening-tls-example-1">
      <title>Example. Configuring TLS access to the controller</title>
      <programlisting>[ssl]
ca_file = cafile.pem
cert_file = certfile.crt
key_file = keyfile.key</programlisting>
    </section>
  </section>
  <section xml:id="data-processing-configuration-and-hardening-role-based-access-control-policies">
    <title>Role-based access control policies</title>
    <para>
      The Data processing service uses a policy file, as described in
      <xref linkend="identity-policies"/>, to configure role-based access
      control. Using the policy file an operator can restrict a group’s
      access to specific data processing functionality.
    </para>
    <para>
      The reasons for doing this will change depending on the organizational
      requirements of the installation. In general, these fine
      grained controls are used in situations where an operator needs to
      restrict the creation, deletion, and retrieval of the Data processing
      service resources. Operators who need to restrict access within a project
      should be fully aware that there will need to be alternative means for
      users to gain access to the core functionality of the service (for
      example, provisioning clusters).
    </para>
    <section xml:id="data-processing-configuration-and-hardening-role-based-access-control-policies-example-1">
      <title>Example. Allow all methods to all users (default policy)</title>
      <programlisting>{
  "default": ""
}</programlisting>
    </section>
    <section xml:id="data-processing-configuration-and-hardening-role-based-access-control-policies-example-2">
      <title>Example. Disallow image registry manipulations to non-admin users</title>
      <programlisting>{
  "default": "",

  "images:register": "role:admin",
  "images:unregister": "role:admin",
  "images:add_tags": "role:admin",
  "images:remove_tags": "role:admin"
}</programlisting>
    </section>
  </section>
  <section xml:id="data-processing-configuration-and-hardening-security-groups">
    <title>Security groups</title>
    <para>
      The Data processing service allows for the association of security
      groups with instances provisioned for its clusters. With no additional
      configuration the service will use the default security group for any
      project that provisions clusters. A different security group may be
      used if requested, or an automated option exists which instructs the
      service to create a security group based on ports specified by the
      framework being accessed.
    </para>
    <para>
      For production environments we recommend controlling the security
      groups manually and creating a set of group rules that are appropriate
      for the installation. In this manner the operator can ensure that the
      default security group will contain all the appropriate rules. For an
      expanded discussion of security groups please see
      <xref linkend="networking-services-security-best-practices-security-groups"/>.
    </para>
  </section>
  <section xml:id="data-processing-configuration-and-hardening-proxy-domains">
    <title>Proxy domains</title>
    <para>
      When using the Object Storage service in conjunction with data
      processing it is necessary to add credentials for the store access.
      With proxy domains the Data processing service can instead use a
      delegated trust from the Identity service to allow store access via a
      temporary user created in the domain. For this delegation mechanism to
      work the Data processing service must be configured to use proxy
      domains and the operator must configure an identity domain for the
      proxy users.
    </para>
    <para>
      The data processing controller retains temporary storage of the
      username and password provided for object store access. When using proxy
      domains the controller will generate this pair for the proxy user, and
      the access of this user will be limited to that of the identity trust.
      We recommend using proxy domains in any installation where the
      controller or its database have routes to or from public networks.
    </para>
    <section xml:id="data-processing-configuration-and-hardening-proxy-domains-example-1">
      <title>Example. Configuring for a proxy domain named “dp_proxy”</title>
      <programlisting>[DEFAULT]
use_domain_for_proxy_users = true
proxy_user_domain_name = dp_proxy
proxy_user_role_names = Member</programlisting>
    </section>
  </section>
  <section xml:id="data-processing-configuration-and-hardening-custom-network-topologies">
    <title>Custom network topologies</title>
    <para>
      The data processing controller can be configured to use proxy commands
      for accessing its cluster instances. In this manner custom network
      topologies can be created for installations which will not use the
      networks provided directly by the Networking service. We recommend
      using this option for installations which require limiting access
      between the controller and the instances.
    </para>
    <section xml:id="data-processing-configuration-and-hardening-custom-network-topologies-example-1">
      <title>Example. Access instances through a specified relay machine</title>
      <programlisting>[DEFAULT]
proxy_command='ssh relay-machine-{tenant_id} nc {host} {port}'</programlisting>
    </section>
    <section xml:id="data-processing-configuration-and-hardening-custom-network-topologies-example-2">
      <title>Example. Access instances through a custom network namespace</title>
      <programlisting>[DEFAULT]
proxy_command='ip netns exec ns_for_{network_id} nc {host} {port}'</programlisting>
    </section>
  </section>
  <section xml:id="data-processing-configuration-and-hardening-indirect-access">
    <title>Indirect access</title>
    <para>
      For installations in which the controller will have limited access to
      all the instances of a cluster, due to limits on floating IP addresses
      or security rules, indirect access may be configured. This allows some
      instances to be designated as proxy gateways to the other instances of
      the cluster.
    </para>
    <para>
      This configuration can only be enabled while defining the node group
      templates that will make up the data processing clusters. It is
      provided as a run time option to be enabled during the cluster
      provisioning process.
    </para>
  </section>
  <section xml:id="data-processing-configuration-and-hardening-rootwrap">
    <title>Rootwrap</title>
    <para>
      When creating custom topologies for network access it can be necessary
      to allow non-root users the ability to run the proxy commands. For
      these situations the oslo rootwrap package is used to provide a
      facility for non-root users to run privileged commands. This
      configuration requires the user associated with the data processing
      controller application to be in the sudoers list and for the option to
      be enabled in the configuration file. Optionally, an alternative
      rootwrap command can be provided.
    </para>
    <section xml:id="data-processing-configuration-and-hardening-rootwrap-example-1">
      <title>Example. Enabling rootwrap usage and showing the default command</title>
      <programlisting>[DEFAULT]
use_rootwrap=True
rootwrap_command=’sudo sahara-rootwrap /etc/sahara/rootwrap.conf’</programlisting>
      <para>
        For more information on the rootwrap project, please see the official
        documentation:
      </para>
      <para>
        <link xlink:href="https://wiki.openstack.org/wiki/Rootwrap">
          https://wiki.openstack.org/wiki/Rootwrap
        </link>
      </para>
    </section>
  </section>
  <section xml:id="data-processing-configuration-and-hardening-logging">
    <title>Logging</title>
    <para>
      Monitoring the output of the service controller is a powerful forensic
      tool, as described more thoroughly in
      <xref linkend="monitoring-logging"/>. The Data processing
      service controller offers a few options for setting the location and
      level of logging.
    </para>
    <section xml:id="data-processing-configuration-and-hardening-logging-example-1">
      <title>Example. Setting the log level higher than warning and specifying an output file.</title>
      <programlisting>[DEFAULT]
verbose = true
log_file = /var/log/data-processing.log</programlisting>
    </section>
  </section>
  <section xml:id="data-processing-configuration-and-hardening-references">
    <title>References</title>
    <para>
      Sahara project documentation:
      <link xlink:href="http://docs.openstack.org/developer/sahara">
        http://docs.openstack.org/developer/sahara
      </link>
    </para>
    <para>
      Hadoop project:
      <link xlink:href="https://hadoop.apache.org/">
        https://hadoop.apache.org/
      </link>
    </para>
    <para>
      Hadoop secure mode docs:
      <link xlink:href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SecureMode.html">
        https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SecureMode.html
      </link>
    </para>
    <para>
      Hadoop HDFS documentation:
      <link xlink:href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">
        https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html
      </link>
    </para>
    <para>
      Spark project:
      <link xlink:href="https://spark.apache.org/">
        https://spark.apache.org/
      </link>
    </para>
    <para>
      Spark security documentation:
      <link xlink:href="https://spark.apache.org/docs/latest/security.html">
        https://spark.apache.org/docs/latest/security.html
      </link>
    </para>
    <para>
      Storm project:
      <link xlink:href="https://storm.apache.org/">
        https://storm.apache.org/
      </link>
    </para>
    <para>
      Zookeeper project:
      <link xlink:href="https://zookeeper.apache.org/">
        https://zookeeper.apache.org/
      </link>
    </para>
    <para>
      Oozie project:
      <link xlink:href="https://oozie.apache.org/">
        https://oozie.apache.org/
      </link>
    </para>
    <para>
      Hive
      <link xlink:href="https://hive.apache.org/">
        https://hive.apache.org/
      </link>
    </para>
    <para>
      Pig
      <link xlink:href="https://pig.apache.org/">
        https://pig.apache.org/
      </link>
    </para>
    <para>
      Cloudera CDH documentation:
      <link xlink:href="https://www.cloudera.com/content/cloudera/en/documentation.html#CDH">
        https://www.cloudera.com/content/cloudera/en/documentation.html#CDH
      </link>
    </para>
    <para>
      Hortonworks Data Platform documentation:
      <link xlink:href="http://docs.hortonworks.com/">
        http://docs.hortonworks.com/
      </link>
    </para>
    <para>
      MapR project:
      <link xlink:href="https://www.mapr.com/products/mapr-distribution-including-apache-hadoop">
        https://www.mapr.com/products/mapr-distribution-including-apache-hadoop
      </link>
    </para>
  </section>
</section>
